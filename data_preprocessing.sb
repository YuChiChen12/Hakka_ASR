#!/bin/bash
#SBATCH --account=GOV113054
#SBATCH --job-name="T1_d2_data_preprocessing"
#SBATCH --partition=dev
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --time=00:30:00
#SBATCH --mem=16G
#SBATCH --output=logs/%x_%j.out
#SBATCH --error=logs/%x_%j.err

# ====== 可調參數 ======
CONDA_ENV_NAME="hakka_asr"
# DATA_DIR="/work/raytsai0214/data/FSR-2025-Hakka-train"
DATA_DIR="data/dataset_2"
DATA_DIR2="dataset_2"
RAW_DATA_DIR="$DATA_DIR"
OUTPUT_CSV="data/$DATA_DIR2.csv"

# ====== 建立必要資料夾 ======
mkdir -p data

# ====== 啟用 conda 環境 ======
ml load miniconda3/24.11.1
conda activate "$CONDA_ENV_NAME"

# # ====== 下載資料 ======
# cd "$DATA_DIR"
# if [ ! -d "$DATA_DIR2" ]; then
#     git clone https://speech.nchc.org.tw/FSR-2025/FSR-2025-Hakka-train
# else
#     echo "$DATA_DIR2 already exists, skipping clone."
# fi
# cd -  # 回到原專案目錄

# ====== 執行資料預處理 ======
if [ ! -f "$OUTPUT_CSV" ]; then
    echo "Running data preparation..."
    python data_prepare.py --raw_data_dir "$RAW_DATA_DIR" --output_csv "$OUTPUT_CSV"
else
    echo "Output CSV already exists ($OUTPUT_CSV), skipping data preparation."
fi
