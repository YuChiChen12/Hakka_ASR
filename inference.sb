#!/bin/bash
#SBATCH --account=GOV113054
#SBATCH --job-name="T1_d1_inference"
#SBATCH --partition=dev
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --time=00:30:00
#SBATCH --mem=16G
#SBATCH --output=logs/%x_%j.out
#SBATCH --error=logs/%x_%j.err

# ====== 可調參數 ======
CONDA_ENV_NAME="hakka_asr"
TRACK=1
INFERENCE_DATA="dataset_1_val_track$TRACK"
INFEERENCE_RESULT="result/inference/$INFERENCE_DATA.csv"

# ====== 建立必要資料夾 ======
mkdir -p data logs result/inference

# ====== 啟用 conda 環境 ======
ml load miniconda3/24.11.1
conda activate "$CONDA_ENV_NAME"

# ====== Inference ======
# python inference.py --csv_path data/test.csv --verbose
python inference.py --model_path formospeech/whisper-large-v3-taiwanese-hakka --csv_path "data/$INFERENCE_DATA.csv" --output_file "$INFEERENCE_RESULT" --verbose
